{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25229c7",
   "metadata": {},
   "source": [
    " <h1><center> Natural Language Processing <br><br> TP1 </center><h1> <i>BAHI Brahim</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "095c42bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bahib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     author_id  inbound                      created_at  \\\n",
       "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @AppleSupport causing the reply to be disregar...            119236   \n",
       "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2  @76328 I really hope you all change but I'm su...            119238   \n",
       "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4  @VirginTrains see attached error message. I've...            119243   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      NaN  \n",
       "1                 119239.0  \n",
       "2                      NaN  \n",
       "3                 119242.0  \n",
       "4                 119240.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "# Load the dataset\n",
    "df = pd.read_csv('sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfb2dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    # Remove common stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4b672db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AppleSupport causing reply disregarded tapped notification keyboard opened'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['text'].apply(deEmojify).apply(preprocess_text)\n",
    "df['cleaned_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "421853cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "def stem_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c245fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eaef9754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>nltk_stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>AppleSupport causing reply disregarded tapped ...</td>\n",
       "      <td>[AppleSupport, causing, reply, disregarded, ta...</td>\n",
       "      <td>[AppleSupport, cause, reply, disregard, tap, n...</td>\n",
       "      <td>[applesupport, caus, repli, disregard, tap, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>business means lot us Please DM name zip code ...</td>\n",
       "      <td>[business, means, lot, us, Please, DM, name, z...</td>\n",
       "      <td>[business, mean, lot, we, please, DM, name, zi...</td>\n",
       "      <td>[busi, mean, lot, us, pleas, dm, name, zip, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>really hope change Im sure wont dont</td>\n",
       "      <td>[really, hope, change, I, m, sure, wo, nt, do,...</td>\n",
       "      <td>[really, hope, change, I, m, sure, wo, nt, do,...</td>\n",
       "      <td>[realli, hope, chang, im, sure, wont, dont]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>LiveChat online moment httpstcoSYVtUKq contact...</td>\n",
       "      <td>[LiveChat, online, moment, httpstcoSYVtUKq, co...</td>\n",
       "      <td>[livechat, online, moment, httpstcosyvtukq, co...</td>\n",
       "      <td>[livechat, onlin, moment, httpstcosyvtukq, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>VirginTrains see attached error message Ive tr...</td>\n",
       "      <td>[VirginTrains, see, attached, error, message, ...</td>\n",
       "      <td>[virgintrain, see, attach, error, message, I, ...</td>\n",
       "      <td>[virgintrain, see, attach, error, messag, ive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>@105860 I wish Amazon had an option of where I...</td>\n",
       "      <td>wish Amazon option get shipped ups store avoid...</td>\n",
       "      <td>[wish, Amazon, option, get, shipped, ups, stor...</td>\n",
       "      <td>[wish, Amazon, option, get, ship, up, store, a...</td>\n",
       "      <td>[wish, amazon, option, get, ship, up, store, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>They reschedule my shit for tomorrow https://t...</td>\n",
       "      <td>reschedule shit tomorrow httpstcoRsvZcTt</td>\n",
       "      <td>[reschedule, shit, tomorrow, httpstcoRsvZcTt]</td>\n",
       "      <td>[reschedule, shit, tomorrow, httpstcoRsvZcTt]</td>\n",
       "      <td>[reschedul, shit, tomorrow, httpstcorsvzctt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>@105861 Hey Sara, sorry to hear of the issues ...</td>\n",
       "      <td>Hey Sara sorry hear issues ask lay speed websi...</td>\n",
       "      <td>[Hey, Sara, sorry, hear, issues, ask, lay, spe...</td>\n",
       "      <td>[hey, Sara, sorry, hear, issue, ask, lay, spee...</td>\n",
       "      <td>[hey, sara, sorri, hear, issu, ask, lay, speed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>@Tesco bit of both - finding the layout cumber...</td>\n",
       "      <td>Tesco bit finding layout cumbersome removing i...</td>\n",
       "      <td>[Tesco, bit, finding, layout, cumbersome, remo...</td>\n",
       "      <td>[tesco, bit, find, layout, cumbersome, remove,...</td>\n",
       "      <td>[tesco, bit, find, layout, cumbersom, remov, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>@105861 If that doesn't help please DM your fu...</td>\n",
       "      <td>doesnt help please DM full name address email ...</td>\n",
       "      <td>[does, nt, help, please, DM, full, name, addre...</td>\n",
       "      <td>[do, nt, help, please, DM, full, name, address...</td>\n",
       "      <td>[doesnt, help, pleas, dm, full, name, address,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   @AppleSupport causing the reply to be disregar...   \n",
       "1   @105835 Your business means a lot to us. Pleas...   \n",
       "2   @76328 I really hope you all change but I'm su...   \n",
       "3   @105836 LiveChat is online at the moment - htt...   \n",
       "4   @VirginTrains see attached error message. I've...   \n",
       "..                                                ...   \n",
       "88  @105860 I wish Amazon had an option of where I...   \n",
       "89  They reschedule my shit for tomorrow https://t...   \n",
       "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
       "91  @Tesco bit of both - finding the layout cumber...   \n",
       "92  @105861 If that doesn't help please DM your fu...   \n",
       "\n",
       "                                         cleaned_text  \\\n",
       "0   AppleSupport causing reply disregarded tapped ...   \n",
       "1   business means lot us Please DM name zip code ...   \n",
       "2                really hope change Im sure wont dont   \n",
       "3   LiveChat online moment httpstcoSYVtUKq contact...   \n",
       "4   VirginTrains see attached error message Ive tr...   \n",
       "..                                                ...   \n",
       "88  wish Amazon option get shipped ups store avoid...   \n",
       "89           reschedule shit tomorrow httpstcoRsvZcTt   \n",
       "90  Hey Sara sorry hear issues ask lay speed websi...   \n",
       "91  Tesco bit finding layout cumbersome removing i...   \n",
       "92  doesnt help please DM full name address email ...   \n",
       "\n",
       "                                       tokenized_text  \\\n",
       "0   [AppleSupport, causing, reply, disregarded, ta...   \n",
       "1   [business, means, lot, us, Please, DM, name, z...   \n",
       "2   [really, hope, change, I, m, sure, wo, nt, do,...   \n",
       "3   [LiveChat, online, moment, httpstcoSYVtUKq, co...   \n",
       "4   [VirginTrains, see, attached, error, message, ...   \n",
       "..                                                ...   \n",
       "88  [wish, Amazon, option, get, shipped, ups, stor...   \n",
       "89      [reschedule, shit, tomorrow, httpstcoRsvZcTt]   \n",
       "90  [Hey, Sara, sorry, hear, issues, ask, lay, spe...   \n",
       "91  [Tesco, bit, finding, layout, cumbersome, remo...   \n",
       "92  [does, nt, help, please, DM, full, name, addre...   \n",
       "\n",
       "                                      lemmatized_text  \\\n",
       "0   [AppleSupport, cause, reply, disregard, tap, n...   \n",
       "1   [business, mean, lot, we, please, DM, name, zi...   \n",
       "2   [really, hope, change, I, m, sure, wo, nt, do,...   \n",
       "3   [livechat, online, moment, httpstcosyvtukq, co...   \n",
       "4   [virgintrain, see, attach, error, message, I, ...   \n",
       "..                                                ...   \n",
       "88  [wish, Amazon, option, get, ship, up, store, a...   \n",
       "89      [reschedule, shit, tomorrow, httpstcoRsvZcTt]   \n",
       "90  [hey, Sara, sorry, hear, issue, ask, lay, spee...   \n",
       "91  [tesco, bit, find, layout, cumbersome, remove,...   \n",
       "92  [do, nt, help, please, DM, full, name, address...   \n",
       "\n",
       "                                    nltk_stemmed_text  \n",
       "0   [applesupport, caus, repli, disregard, tap, no...  \n",
       "1   [busi, mean, lot, us, pleas, dm, name, zip, co...  \n",
       "2         [realli, hope, chang, im, sure, wont, dont]  \n",
       "3   [livechat, onlin, moment, httpstcosyvtukq, con...  \n",
       "4   [virgintrain, see, attach, error, messag, ive,...  \n",
       "..                                                ...  \n",
       "88  [wish, amazon, option, get, ship, up, store, a...  \n",
       "89       [reschedul, shit, tomorrow, httpstcorsvzctt]  \n",
       "90  [hey, sara, sorri, hear, issu, ask, lay, speed...  \n",
       "91  [tesco, bit, find, layout, cumbersom, remov, i...  \n",
       "92  [doesnt, help, pleas, dm, full, name, address,...  \n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tokenization\n",
    "df[\"tokenized_text\"] = df[\"cleaned_text\"].apply(tokenize_text)\n",
    "\n",
    "# Apply lemmatization\n",
    "df[\"lemmatized_text\"] = df[\"cleaned_text\"].apply(lemmatize_text)\n",
    "\n",
    "df[\"nltk_stemmed_text\"] = df[\"cleaned_text\"].apply(lambda text: [stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[[\"text\",\"cleaned_text\",\"tokenized_text\",\"lemmatized_text\",\"nltk_stemmed_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5bf05",
   "metadata": {},
   "source": [
    "## Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e5332d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "\n",
      "@105840 You're welcome! If there's anything else we can help with, just give us a shout. We're here for you ðŸ˜‰ /CP \n",
      "\n",
      " Cleaned Text (No punctuation nor emojis) \n",
      "\n",
      "Youre welcome theres anything else help give us shout CP \n",
      "\n",
      "Tokenization\n",
      "\n",
      "['You', 're', 'welcome', 'there', 's', 'anything', 'else', 'help', 'give', 'us', 'shout', 'CP'] \n",
      "\n",
      "Lemmatization\n",
      "\n",
      "['you', 'be', 'welcome', 'there', 's', 'anything', 'else', 'help', 'give', 'we', 'shout', 'CP'] \n",
      "\n",
      "Stemming\n",
      "\n",
      "['your', 'welcom', 'there', 'anyth', 'els', 'help', 'give', 'us', 'shout', 'cp'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Text\\n\")\n",
    "print(df.text[21],'\\n')\n",
    "print(\" Cleaned Text (No punctuation nor emojis) \\n\")\n",
    "print(df.cleaned_text[21],'\\n')\n",
    "print(\"Tokenization\\n\")\n",
    "print(df.tokenized_text[21],'\\n')\n",
    "print(\"Lemmatization\\n\")\n",
    "print(df.lemmatized_text[21],'\\n')\n",
    "print(\"Stemming\\n\")\n",
    "print(df.nltk_stemmed_text[21],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbcfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
